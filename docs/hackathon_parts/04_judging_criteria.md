# ハッカソン審査基準分析

> **作成**: 足軽4号 (subtask_068_04)
> **日時**: 2026-02-10
> **対象**: 第4回 Agentic AI Hackathon with Google Cloud

---

## 調査結果

### 1. 公式審査基準（3項目・均等配分）

第4回 Agentic AI Hackathon with Google Cloud の公式審査基準は以下の3項目。各33%均等配分と推定される（過去回と同一構造）。

| # | 基準名 | 内容 | 評価ポイント |
|---|--------|------|-------------|
| 1 | **課題の新規性** | 未解決の社会課題の発見 | 多くの人が直面する未解決の課題に取り組んでいるか |
| 2 | **解決策の有効性** | 提案ソリューションの実効性 | 課題を明確に定義し、効果的に解決しているか |
| 3 | **実装品質と拡張性** | 技術的完成度と発展性 | 必須GCPツールの活用度、スケーラビリティ、コスト効率 |

### 2. 一般的なハッカソン審査基準（WebSearch結果）

複数のハッカソンプラットフォーム（TAIKAI, Devpost, ODSC, Microsoft等）を横断調査した結果、共通する評価カテゴリは以下の通り。

| カテゴリ | 一般的配分 | 説明 |
|----------|-----------|------|
| アイデア品質/革新性 | 20-25% | 創造性、独自性、アプローチの新規性 |
| 課題定義と解決有効性 | 20-25% | 課題の明確さ、ソリューションの実効性 |
| 技術実装 | 15-20% | コード品質、アーキテクチャ、技術活用度 |
| インパクト/実現可能性 | 15-20% | 実世界での適用性、スケーラビリティ |
| プレゼン/デモ | 10-15% | ピッチ品質、デモ動画、ドキュメント |
| デザイン/UX | 5-10% | ユーザー体験、アクセシビリティ |

### 3. Google Cloud Japan AI Hackathon 固有の知見

過去回の入賞作品分析・受賞者インタビューから判明した重要ポイント:

1. **「技術力よりもアイデアや課題解決能力」** — 技術的に高度でも課題定義が弱いと評価されない
2. **Human-in-the-Loop設計** — 人とAIの役割分離が明確な作品が高評価
3. **Zenn記事の品質が審査に直結** — ブログ構成が審査評価に大きく影響
4. **具体的な定量効果** — 受賞作ManabiyaAIは「作業時間約85%削減」を明示
5. **ドメイン専門性 + 技術深度** — 表面的なAPI利用より、GCPサービスの戦略的組合せ
6. **production-ready志向** — ADKハッカソン審査員は「既存パイプラインに統合可能な実用ツール」を重視

### 4. 受賞戦略（Zenn受賞者の3戦略）

1. **審査基準の逆算設計**: 公式基準をLLMに入力し、各基準に刺さるコンセプトを反復開発
2. **AI支援開発**: 不慣れな技術をAIコーディングアシスタント（Cursor等）で高速実装
3. **AI模擬審査**: 提出前にAIで記事を公式基準ベースで模擬審査し、弱点を修正

---

## スコアリング

### 公式3基準（最重要）

| 基準 | 現状スコア(1-10) | 根拠 | 改善ポイント | 目標スコア |
|------|:---:|------|-------------|:---:|
| **課題の新規性** | **8** | 「AIが止まる」はAI全自動化のトレンドに逆行する独自アプローチ。固定資産判定という具体的な未解決課題を選定。ただし課題自体（固定資産分類）は既知の会計業務であり、「未解決の社会課題」としての新規性訴求がやや弱い | Zenn記事で「なぜ今この課題なのか」を社会的文脈（インボイス制度、電帳法対応で経理負荷増大）と紐付けて訴求する | **9** |
| **解決策の有効性** | **8** | Agentic 5-Stepプロセス（止まる→根拠提示→質問→再判定→DIFF）は論理的に一貫。Golden Set 100%正答率。67%時間削減の定量効果を明示。ただし検証データ10件のみ、実ユーザーでの検証なし | Golden Setを15-20件に拡充。1-2件の実データ風テストケースを追加し、説得力を強化 | **9** |
| **実装品質と拡張性** | **7** | Cloud Run稼働中、FastAPI+Streamlitのクリーンな構成、Feature Flag設計で拡張可能。Gemini 3 Pro thinking_level=HIGH。セキュリティ4件修正済（認証/パストラバーサル/アップロード検証/インジェクション対策）。**しかし** PDF分類・Document AI・Vertex AI Searchが全てOFF状態。GCPサービス活用が実質Cloud Run + Gemini APIのみに見える | PDF分類(`PDF_CLASSIFY_ENABLED=1`)を有効化してデモ。Vertex AI Searchも可能なら有効化し、GCPサービス活用の幅を審査員に見せる。最低限3つのGCPサービスが動作状態であることが理想 | **8** |

### 補足基準（一般的評価軸）

| 基準 | 現状スコア(1-10) | 根拠 | 改善ポイント | 目標スコア |
|------|:---:|------|-------------|:---:|
| **技術力** | **8** | Gemini 3 Pro Preview + thinking_level=HIGH（最新AI活用）、System Prompt Engineering（税務知識注入）、構造化JSON出力強制、セキュリティ多層防御（API認証/パストラバーサル/マジックバイト検証/プロンプトサニタイズ/CORS/レート制限）、構造化ログ導入。技術選択の合理性が高い | Vertex AI SearchやDocument AIの統合を実動作させると技術力の印象がさらに向上 | **9** |
| **完成度** | **6** | API+UIがCloud Runで稼働中。デモデータ・デモ台本準備済。コンポーネント設計のUI。**しかし** Zenn記事未作成、YouTubeデモ動画未作成（ともに必須提出物）、PDF/DocAI/VertexSearch無効状態。提出物3点中1点（GitHub）のみ確定 | 【最優先】Zenn記事執筆+YouTubeデモ動画撮影。Feature Flag有効化でデモの完成度向上 | **8** |
| **独自性・創造性** | **9** | 「AIが止まることを価値とする」は審査員の既存認識を覆す逆説的コンセプト。3値判定（CAPITAL_LIKE/EXPENSE_LIKE/GUIDANCE）は二択AIの常識に挑戦。Before/After DIFFによる監査証跡は実務的に独自。Stop-first設計思想はAIエージェント分野で稀有 | Zenn記事でこの独自性を冒頭に強く訴求。「他のAIは答えを出す。このAIは止まる」のキャッチコピーを活用 | **9** |
| **実用性・インパクト** | **7** | ターゲットユーザー明確（中小企業経理部門・会計事務所）。定量効果（67%時間削減、年間40-200時間、12-80万円）を算出済。日本の会計実務に即した設計。ただしドメインがニッチ（固定資産判定）、実ユーザーテスト未実施 | Zenn記事で「中小企業360万社の経理担当者」等の市場規模を示し、インパクトの大きさを訴求 | **8** |
| **プレゼン・デモ** | **5** | デモ台本（DEMO_RUNBOOK.md）あり、3-4分のシナリオ設計済。審査員向け戦略文書（judge_value_proposition.md）準備済。**しかし** 必須のYouTube3分デモ動画が未作成。必須のZenn記事が未作成。これは致命的 — 提出要件を満たさないと審査対象外になるリスク | 【最最優先】3分デモ動画撮影（DEMO_RUNBOOK.mdベース）+Zenn記事執筆（カテゴリIdea、トピックgch4、アーキテクチャ図必須）。動画ではStop→質問→再判定→DIFFの一連フローを見せる | **8** |
| **ビジネス性** | **6** | ROI算出済（年間12-80万円削減）。明確なマネタイズ対象。会計SaaSへの組込み可能。ただし競合分析なし、価格戦略なし、市場規模の明示なし | Zenn記事の結論部で「既存会計ソフトへのアドオン」としてのビジネス展開をさらりと言及 | **7** |

---

## 総合評価

### スコアサマリ

| 区分 | 基準 | 現状 | 目標 | GAP |
|------|------|:---:|:---:|:---:|
| 公式 | 課題の新規性 | 8 | 9 | +1 |
| 公式 | 解決策の有効性 | 8 | 9 | +1 |
| 公式 | 実装品質と拡張性 | 7 | 8 | +1 |
| 補足 | 技術力 | 8 | 9 | +1 |
| 補足 | 完成度 | 6 | 8 | +2 |
| 補足 | 独自性・創造性 | 9 | 9 | 0 |
| 補足 | 実用性・インパクト | 7 | 8 | +1 |
| 補足 | プレゼン・デモ | 5 | 8 | +3 |
| 補足 | ビジネス性 | 6 | 7 | +1 |

**公式基準平均**: 7.7 / 10（目標: 8.7）
**全基準平均**: 7.1 / 10（目標: 8.3）

### 強み（Strengths）

1. **Stop-first設計思想の独自性**: 「AIが止まる」は他の出場者と明確に差別化できるコンセプト。審査基準「課題の新規性」に直接刺さる
2. **Agentic 5-Stepの論理的一貫性**: 止まる→聞く→変わる→DIFFの流れが明確で、「解決策の有効性」を構造的に示せる
3. **技術選択の合理性**: Gemini 3 Pro thinking_level=HIGH、構造化JSON出力、System Prompt Engineeringの組合せが税務判定に最適化されている
4. **セキュリティの多層防御**: cmd_067での22件修正により、実運用レベルのセキュリティを確保。審査員に「本気のプロダクト」と印象付けられる
5. **定量効果の明示**: 67%時間削減、年間40-200時間という具体数値は説得力がある

### 弱み（Weaknesses）

1. **【致命的】必須提出物の未完成**: Zenn記事もYouTubeデモ動画も未作成。提出要件を満たさなければ審査対象外
2. **GCPサービス活用の薄さ**: 実質Cloud Run + Gemini APIのみ稼働。PDF/DocAI/VertexSearchが全てOFF。「実装品質と拡張性」で減点リスク
3. **検証データの少なさ**: Golden Set 10件は統計的に不十分。「100%正答率」の主張が10件では説得力に欠ける
4. **実ユーザー検証の不在**: 定量効果はシミュレーション値。実ユーザーでの検証がないと「有効性」の説得力が限定的
5. **ニッチ領域**: 固定資産判定は会計専門家以外には直感的に理解しにくい。Zenn記事での分かりやすい説明が不可欠

---

## 改善優先度

### 最優先（締切までに必須 — 提出要件）

| 優先度 | 改善項目 | 理由 | 担当推奨 | 所要時間目安 |
|:---:|----------|------|----------|:-----------:|
| **P0** | **Zenn記事執筆** | 必須提出物。カテゴリIdea、トピックgch4。アーキテクチャ図+デモ動画リンク必須。記事品質が審査に直結（受賞者証言） | 専任1名 | 4-6時間 |
| **P0** | **YouTube3分デモ動画** | 必須提出物。DEMO_RUNBOOK.mdベースでStop→質問→再判定→DIFFを実演。Zenn記事に埋込 | 専任1名 | 2-3時間 |
| **P0** | **GitHubリポジトリ公開確認** | 公開状態で2026/3/2まで維持。README整備済だが公開設定の最終確認が必要 | 確認のみ | 15分 |

### 高優先（スコア大幅向上）

| 優先度 | 改善項目 | 影響基準 | 期待スコア向上 |
|:---:|----------|----------|:-----------:|
| **P1** | PDF分類機能の有効化（`PDF_CLASSIFY_ENABLED=1`） | 実装品質 +1 | 7→8 |
| **P1** | Vertex AI Search有効化（法令エビデンス検索） | 実装品質 +1, 技術力 +1 | GCPサービス3個以上に |
| **P1** | Golden Set拡充（10件→20件） | 解決策有効性 +0.5 | 説得力向上 |

### 中優先（差別化強化）

| 優先度 | 改善項目 | 影響基準 | 備考 |
|:---:|----------|----------|------|
| **P2** | Zenn記事で社会的文脈訴求（インボイス制度・電帳法） | 課題新規性 +1 | 記事内で対応 |
| **P2** | 市場規模の明示（中小企業360万社） | 実用性 +1 | 記事内で対応 |
| **P2** | 競合比較（既存会計ソフトとの差別化） | ビジネス性 +0.5 | 記事内で対応 |

### 注意事項

- **締切は2026年2月15日（あと5日）** — P0項目は全て2/13までに完了必須（バッファ2日）
- **Zenn記事はP0かつ最もROIが高い** — 審査員は記事を精読する。記事品質 = 審査結果と考えてよい
- **Feature Flag有効化はデプロイコマンド1行** — 有効化自体は容易。ただし動作確認が必要
- **AI模擬審査の推奨** — 受賞者の成功戦略に倣い、記事完成後にLLMで公式3基準ベースの模擬審査を実施すべき

---

## 参考資料（WebSearch出典）

- [第4回 Agentic AI Hackathon with Google Cloud](https://zenn.dev/hackathons/google-cloud-japan-ai-hackathon-vol4)
- [AI Agent Hackathon 受賞者の3つの受賞戦略](https://zenn.dev/kikagaku/articles/d2876e8e2e50a5)
- [第2回AI Agent Hackathon 振り返りと成功のヒント](https://zenn.dev/taku_sid/articles/20250403_ai_hackathon_review)
- [ADK Hackathon Results, Winners and Highlights](https://cloud.google.com/blog/products/ai-machine-learning/adk-hackathon-results-winners-and-highlights)
- [TAIKAI: 6 Hackathon Judging Criteria](https://taikai.network/en/blog/hackathon-judging)
- [Devpost: Understanding Hackathon Judging Criteria](https://info.devpost.com/blog/understanding-hackathon-submission-and-judging-criteria)
- [Ethical AI Hackathon Judging Rubric (CGU)](https://research.cgu.edu/hackathon/home/judging-rubric/)
- [ODSC-Google Cloud Hackathon 2025 Winners](https://opendatascience.com/insights-from-the-winners-of-the-2025-odsc-google-cloud-hackathon/)
