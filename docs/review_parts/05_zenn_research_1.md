# Zenn先行事例調査（Part 1: 固定資産・経費・PDF分類）

## 調査サマリ

- 5キーワードで計50件の検索結果を取得し、そのうち技術的に関連性の高い**10記事を精読分析**した
- 請求書OCR+LLM領域の記事が最も充実しており、「OCRで抽出→LLMで構造化→ルールベースで検証」という**三層アーキテクチャ**が主流パターンとして浮上
- fixed-asset-ashigaruの技術スタック（Streamlit+FastAPI+LLM）は妥当だが、**OCR精度の担保**と**判定結果の視覚的検証UI**に改善余地あり

## 発見した記事一覧

---

### 記事1: AIがレシート仕分けしてくれるサービスを作ってみた

- **URL**: https://zenn.dev/5hige99/articles/58212a00887146
- **技術スタック**:
  - フロントエンド: React + TypeScript
  - バックエンド: Cloud Functions (Node.js)
  - OCR: Google Cloud Document AI
  - DB: Firestore（リアルタイム同期）
- **設計アプローチ**:
  - 5段階ワークフロー: アップロード→OCR抽出→AI分類→計算→履歴保存
  - AIが過去データに基づき「私費/経費」を自動分類、ユーザーが手動修正可能
  - 修正データがフィードバックループとなり次回分類を最適化
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **フィードバックループによる学習**、Firestoreリアルタイム同期、多フォーマット対応（PDF/JPEG/PNG/BMP/TIFF/GIF）
  - 劣っている点: 分類が「私費/経費」の二値であり、固定資産判定のような複雑な判定ロジックには対応していない
- **取り入れるべき改善点**:
  - ユーザーの修正結果をフィードバックとして判定精度を向上させるメカニズム
  - 多フォーマット対応（現状のPDF以外のファイル形式サポート）

---

### 記事2: 生成AI OCRが「請求書」で実用になった瞬間

- **URL**: https://zenn.dev/counterworks/articles/ebcc67b8ac90c1
- **技術スタック**:
  - LLM: GPT-4o、Gemini 1.5、Claude 3.5 Sonnet（複数比較）
  - 補助: OpenCVによる色領域判定
  - PDF画像化処理
- **設計アプローチ**:
  - PDF読取→構造化→DB照合→候補提示のワークフロー
  - 核心的方針: **「LLMにやらせすぎない（候補生成まで）」**
  - 最終確定は自動またはヒューマンレビュー
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **「LLMの役割を候補生成に限定する」**という設計思想が明確。LLMの幻覚（ハルシネーション）リスクを抑制
  - 劣っている点: ハッカソンレベルのプロトタイプであり、本番運用の実績データなし
- **取り入れるべき改善点**:
  - LLMの役割を「候補生成」に限定し、最終判定は**ルールベース+ヒューマンレビュー**のハイブリッド設計
  - 複数LLMモデルの比較検証プロセスの導入

---

### 記事3: 請求書から漫画まで！OCR+LLMで進化する文書データ構造化技術

- **URL**: https://zenn.dev/mkj/articles/69f88c75f1a814
- **技術スタック**:
  - OCR: Azure Document Intelligence (ADI)
  - LLM: gpt-4o-2024-08-06 / gpt-4o-2024-11-20
  - 比較対象: LlamaParse, pypdfium2, Unstructured, PyPDF
- **設計アプローチ**:
  - 3パイプラインの体系的比較:
    1. ADI単体（テキスト抽出のみ）
    2. LLM単体（画像から直接抽出）
    3. **ADI+LLM**（抽出結果+画像を併用）← 最高精度
  - JSON形式の統一出力スキーマで標準化
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **体系的なパイプライン比較**により最適な処理方式を選定。ADI+LLMの組み合わせが定型文書で最高精度
  - 劣っている点: 非定型文書ではLLM単体が優位という結論であり、固定資産関連書類（見積書・請求書）の多様なフォーマットには対応策の検討が必要
- **取り入れるべき改善点**:
  - OCR（テキスト抽出）とLLM（構造化・判定）の**役割分離アーキテクチャ**
  - Azure Document Intelligenceの採用検討（表構造の認識精度が高い）

---

### 記事4: 非定型AI-OCR作ってみた 〜AI時代の開発戦略を添えて〜

- **URL**: https://zenn.dev/simpleform/articles/20231202-02-empowering-ocr-with-llm
- **技術スタック**:
  - OCR: Google Vision API (document_text_detection)
  - LLM: GPT-4 (gpt-4-1106-preview)
  - ライブラリ: pdf2image, poppler-utils
  - 言語: Python
- **設計アプローチ**:
  - 2段階パイプライン: テキスト抽出（Vision API）→ 構造化処理（GPT-4）
  - **Few-shot Learning**でプロンプトに具体例を含め精度向上
  - 「GPTEntitiesExtractor」クラスによるJSON正規化
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **Few-shot Learning**の採用。具体例テキスト+期待出力のペアをプロンプトに含めることで、固定資産判定でも精度向上が期待できる
  - 劣っている点: 具体的な精度指標なし。UIなし（API設計のみ）
- **取り入れるべき改善点**:
  - Few-shot Learningパターンの固定資産判定プロンプトへの適用
  - システムロール指示に項目定義と特性記述を含める設計

---

### 記事5: 請求書読み取りにおけるOCRとLLMの最適な役割分担

- **URL**: https://zenn.dev/edash_tech_blog/articles/346c03c39c80a9
- **技術スタック**:
  - OCR: Azure Document Intelligence / Azure Computer Vision
  - LLM: GPT-5（検証用）
  - 処理フロー: Document Intelligence → テキスト+表データ → LLM → プログラム（計算）
- **設計アプローチ**:
  - **三層構造で責務を分離**（本調査で最も参考になる設計）:
    1. OCR層: 文字認識・表構造認識（確実な処理）
    2. LLM層: 曖昧な情報の特定・文脈を踏まえた抽出（得意領域に限定）
    3. プログラム層: 計算・バリデーション・検証（ルールベース）
  - LLMに任せない領域を明確化: 文字認識、構造認識、合計計算、税込金額計算
- **精度評価（定量的）**:
  - 900件の請求書サンプルで検証
  - OCR+画像+サーバー計算: **約80%**（最高）
  - OCRのみ（Document Intelligence）: 約70%
  - OCRのみ（Computer Vision）: 約65%
  - 画像のみ（LLM直接）: **約60%**（最低）
  - **重要知見**: 画像情報を追加で渡すメリットは限定的
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **900件での定量評価**、三層構造の明確な責務分離、「LLMに任せすぎない」設計の数値的裏付け
  - 劣っている点: 請求書特化であり、固定資産判定の「資産か経費か」判定ロジックは含まない
- **取り入れるべき改善点**:
  - **三層構造（OCR→LLM→プログラム）の採用が最優先の改善候補**
  - 計算・バリデーションはLLMに任せず、プログラムで確実に処理する設計
  - 定量的な精度評価の導入（テストデータセットの整備）

---

### 記事6: 請求書をOCRで抽出してみた

- **URL**: https://zenn.dev/dotconf/articles/2025-10-20-ocr-invoice-article
- **技術スタック**:
  - OCR: Tesseract + Google Cloud Vision API（2段階）
  - 画像前処理: OpenCV（グレースケール変換、ノイズ除去、二値化）
  - Python: Pytesseract
- **設計アプローチ**:
  - **ハイブリッド戦略**: Tesseractで処理→信頼度が低い場合のみVision APIを使用
  - 正規表現パターンマッチングによる情報抽出
  - 金額バリデーション: 金額範囲検証（100,000〜1,000,000）で妥当性確保
- **精度評価（定量的）**:
  - Tesseract: **約65%**（表形式・複雑レイアウトで誤認識多数）
  - Vision API: **約98%**（レイアウト認識、全角/半角判別で優位）
  - 8軸での多面評価（基本情報抽出、表形式認識、レイアウト理解、処理速度、コスト等）
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: OCRエンジンの**定量比較**（Tesseract vs Vision API）、OpenCVによる前処理パイプライン
  - 劣っている点: LLMによる判定ロジックなし（OCR抽出のみ）
- **取り入れるべき改善点**:
  - OpenCVによる画像前処理の導入（グレースケール、ノイズ除去、二値化）でOCR精度向上
  - 段階的OCR（低コスト→高精度）のフォールバック戦略

---

### 記事7: 論文の分類をするモデルを作ろうとしてみる〜教師データ作成編〜

- **URL**: https://zenn.dev/sakasegawa/articles/29feab76ca9afb
- **技術スタック**:
  - LLM: GPT-3.5（Few-shot教師データ生成）
  - ML候補: 全結合層 / BERTファインチューニング / T5ファインチューニング
  - ツール: arxiv.py, gspread, oauth2client
- **設計アプローチ**:
  - LLMで**教師データを自動生成**し、小型MLモデルで分類する**蒸留アプローチ**
  - 確率付きカテゴリ出力:「Image generation (0.82), Image recognition (0.12)」
  - ソフトラベル正規化: 確率値を12カテゴリに割り当て、合計1.0に補正
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **LLMで教師データ生成→小型モデルで推論**のコスト最適化設計。大量処理時のAPI費用を劇的に削減可能
  - 劣っている点: 論文分類に特化、会計領域の知識なし
- **取り入れるべき改善点**:
  - **蒸留アプローチ**: LLMで固定資産判定の教師データを生成し、小型分類モデルを訓練する将来構想
  - 確率付き出力による判定の信頼度表示

---

### 記事8: 領収書OCRをGeminiとChrome拡張で実装

- **URL**: https://zenn.dev/acntechjp/articles/5b5f116328a372
- **技術スタック**:
  - LLM/OCR: Gemini 2.0 Flash API
  - フロントエンド: Chrome Extension (Manifest V3), Vanilla JavaScript
  - 撮影: Canvas API + MediaDevices.getUserMedia()
- **設計アプローチ**:
  - 直線的ワークフロー: カメラ起動→撮影→OCR解析→CSV保存
  - プロンプトで出力形式を厳密に制御（ダブルクォーテーション指定、N/A指示）
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: 10分以内で実装可能なシンプルさ、モバイル対応（カメラ撮影）
  - 劣っている点: Chrome拡張限定、バリデーションなし、精度評価なし
- **取り入れるべき改善点**:
  - Gemini 2.0 FlashのOCR精度の高さは検討に値する（コスト面でも有利）

---

### 記事9: 領収書OCR管理を機能強化 OCR精度を気軽に確認可能

- **URL**: https://zenn.dev/acntechjp/articles/add0fb7674f195
- **技術スタック**:
  - LLM: Gemini 2.0 Flash / Claude 3.7 Sonnet / ChatGPT-4o（3モデル選択可能）
  - フロントエンド: Chrome Extension (Manifest V3)
  - アーキテクチャ: Service Worker + popup + comparison画面 + options画面
- **設計アプローチ**:
  - **座標付きJSON出力**: 各フィールドの画像上の位置（x,y,幅,高さ）をLLMに出力させる
  - **画像-テキスト対応の視覚的検証**: フォームフィールド選択→画像上の該当部分ハイライト
  - 3つのAIモデルを切り替えて精度比較可能
  - 6フィールド構成: 支払先、発行日、金額（税込）、通貨、登録番号、注記
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: **座標ベースの視覚的検証UI**が非常に優秀。ユーザーが抽出結果の正誤を直感的に確認できる。複数AIモデルの比較機能
  - 劣っている点: 領収書6フィールドに限定、複雑な判定ロジックなし
- **取り入れるべき改善点**:
  - **抽出結果と元文書の対応箇所を視覚的にハイライトする検証UI**（最優先で導入検討すべき）
  - 複数LLMモデルの切り替え・比較機能

---

### 記事10: 経理部門長必見！Excelでの業務効率化を実現する生成AIツール完全ガイド

- **URL**: https://zenn.dev/taku_sid/articles/20250409_excel_ai_accounting
- **技術スタック**:
  - Microsoft Copilot（Microsoft 365統合）
  - ChatGPT / GPT-4o
  - 専門ツール: Docyt（AI Bookkeeper「GARY」）、BizForecast
- **設計アプローチ**:
  - 経理業務全体のAI活用戦略ガイド（概念レベル）
  - 仕訳処理フロー: 取引データ自動分類→勘定科目自動判断→異常値検出
  - リスクスコアリングの言及（詳細ロジックなし）
- **fixed-asset-ashigaruとの比較**:
  - 優れている点: 経理業務全体の俯瞰的な視点、「時間30〜70%削減」「エラー90%以上削減」の効果指標
  - 劣っている点: 概念レベルの記事であり、具体的な実装なし
- **取り入れるべき改善点**:
  - 「勘定科目の自動判断」のアプローチは固定資産判定にも応用可能
  - ROI算出時の効果指標（時間削減率、エラー削減率）の計測設計

---

## 総合分析

### 1. 技術スタックの主流トレンド

| カテゴリ | 主流技術 | 採用記事数 |
|---------|---------|-----------|
| OCR | Azure Document Intelligence / Google Cloud Vision API | 6/10 |
| LLM | GPT-4o系 / Gemini 2.0 Flash | 8/10 |
| 構造化出力 | JSON Schema指定のプロンプト | 7/10 |
| UI | Chrome拡張 / React / なし（API） | 多様 |

### 2. 設計パターンの類型化

**パターンA: LLM直接型**（2記事）
- 画像を直接LLMに入力し、構造化データを出力
- 精度: 約60%（最低）。simple だがハルシネーションリスク高い

**パターンB: OCR+LLMハイブリッド型**（5記事）← 最多・最推奨
- OCRでテキスト抽出→LLMで構造化・判定
- 精度: 約70〜80%。役割分離が明確で安定

**パターンC: 三層型（OCR+LLM+ルール）**（2記事）← 最高精度
- OCR→LLM→プログラム（計算・バリデーション）
- 精度: 約80%（最高）。LLMの弱点をルールで補完

**パターンD: LLM蒸留型**（1記事）
- LLMで教師データ生成→小型モデルで推論
- コスト最適化に優れるが、導入ハードルは高い

### 3. fixed-asset-ashigaruへの提言（優先度順）

#### 最優先（即座に取り入れるべき）

1. **三層構造の採用**: OCR（テキスト抽出）→ LLM（判定・構造化）→ ルールベース（バリデーション・計算）
   - 根拠: 記事5の900件検証で最高精度を記録。LLMの幻覚リスクを最終段のルールで防止
   - 実装案: 金額の閾値判定（10万円/20万円/30万円）はLLMに任せず、プログラムで確実に処理

2. **抽出結果の視覚的検証UI**: 元文書と抽出結果の対応箇所をハイライト表示
   - 根拠: 記事9の座標ベース検証UIが非常に直感的。固定資産判定の「なぜこの判定か」の根拠表示にも応用可能

3. **Few-shot Learningの導入**: 固定資産判定プロンプトに具体的な判定例を含める
   - 根拠: 記事4で精度向上が確認済み。「この請求書は○○の理由で固定資産」という例示が判定を安定化

#### 中期的（次期バージョンで検討）

4. **ユーザーフィードバックループ**: 判定結果の手動修正データを蓄積し、プロンプト改善に活用
   - 根拠: 記事1の自動学習メカニズム

5. **複数LLMモデルの比較検証**: GPT-4o / Gemini / Claudeで同一文書を判定し、精度差を計測
   - 根拠: 記事9の複数モデル対応設計

6. **定量的精度評価の導入**: テストデータセットを整備し、精度を定期計測
   - 根拠: 記事5・6で定量評価が信頼性向上に直結

#### 長期的（将来構想）

7. **蒸留アプローチ**: LLMで判定教師データを生成し、小型モデルで高速推論
   - 根拠: 記事7の蒸留設計。大量処理時のAPI費用削減に有効

### 4. fixed-asset-ashigaruの現状評価

| 観点 | 現状 | 先行事例との比較 |
|------|------|-----------------|
| 技術スタック | Streamlit+FastAPI+LLM | 妥当。Streamlitは迅速なプロトタイプに最適 |
| OCR | PDFテキスト抽出 | OCR専用エンジン（ADI/Vision API）採用で精度向上余地あり |
| 判定ロジック | LLM+ポリシーベース | 二層構造。三層化（+バリデーション層）で精度向上が期待 |
| UI/UX | Streamlit UI | 視覚的検証UI（座標ハイライト）の追加で改善可能 |
| 精度評価 | 不明 | テストデータセット整備が急務 |
