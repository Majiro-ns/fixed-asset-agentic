# Zenn先行事例調査（Part 2: 会計AI・LLM業務・Streamlit活用）

## 調査サマリ

- 6キーワードで計60件超の記事を調査し、**12件を深掘り分析**した
- 会計・経理AI領域では**AI-OCR + LLM分類 + 人間レビュー**のパターンが主流。完全自動化ではなく「AI提案→人間承認」モデルが実務の基本
- Streamlit業務ツールは**Cloudflare Tunnel + Access での社内デプロイ**が現実解として確立されつつあり、FastAPIとの組み合わせでは**オニオンアーキテクチャ**や**MCP対応**が先進的な設計として注目されている

---

## 発見した記事一覧

### 記事1: AIがレシート仕分けしてくれるサービスを作ってみた

- **URL**: https://zenn.dev/5hige99/articles/58212a00887146
- **技術スタック**: React + TypeScript（UI）、Cloud Functions/Node.js（バックエンド）、Google Cloud Document AI（OCR）、Firestore（DB）、Cloud Storage
- **設計アプローチ**:
  - Storage へのアップロードをトリガーに Cloud Functions が起動
  - Document AI で店名・金額・日付・明細を自動抽出（信頼度スコア付き）
  - ユーザーが経費/私費を手動分類 → 過去の分類データで将来の予測を最適化
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: Document AI の信頼度スコアによる品質可視化、イベント駆動アーキテクチャ
  - **劣っている点**: Streamlit 未使用（React ベース）、LLM による高度な判定ロジックなし
- **取り入れるべき改善点**: **OCR信頼度スコアの可視化**。fixed-asset-ashigaru でも PDF 抽出結果の信頼度を UI に表示し、低信頼度の箇所を人間がレビューする仕組みが有効

---

### 記事2: AI-OCRとウェブカメラで領収書をCSV化し会計ソフトにインポート

- **URL**: https://zenn.dev/devneko/articles/2735900b07f99e
- **技術スタック**: Google Gemini（OCR兼構造化）、Vercel（デプロイ）、MoneyForward 連携 CSV 出力
- **設計アプローチ**:
  - Gemini を OCR として使用し、JSON 形式で構造化データを出力
  - 抽出データは編集可能なテーブルで表示（手動補正可能）
  - 参照データを入力することでOCR精度を改善するフィードバックループ
  - クライアントサイド処理（APIキー・画像はサーバー保存なし）
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: LLM（Gemini）を OCR エンジンとして直接活用する発想、会計ソフト連携のCSV出力
  - **劣っている点**: 503エラー多発でレスポンスが遅い、リトライ設計が不十分
- **取り入れるべき改善点**: **LLMをOCR + 構造化の一体エンジンとして活用**する発想。PDF抽出後のテキストをLLMで構造化する際、JSON出力を強制するプロンプト設計が参考になる

---

### 記事3: 経理部門長必見！Excelでの業務効率化を実現する生成AIツール完全ガイド

- **URL**: https://zenn.dev/taku_sid/articles/20250409_excel_ai_accounting
- **技術スタック**: Microsoft Copilot for Excel、ChatGPT/GPT-4 API、Numerous.ai、Docyt、Power Automate
- **設計アプローチ**:
  - **AI仕訳生成**: 明細データから勘定科目を判断し仕訳を自動生成。例外処理も提案
  - **異常検知**: 通常パターンからの外れ値検出、前年同期比異常値自動検出、リスクスコアリング
  - **品質保証**: 「AI提案 → 人間承認」モデル。完全自動化ではなく人間レビュー必須
  - **継続学習**: 人間の修正フィードバックで精度向上するサイクル
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: 異常検知・リスクスコアリング機能、継続学習サイクルの設計
  - **劣っている点**: Excel依存のため柔軟性に限界、専用UIなし
- **取り入れるべき改善点**: **判定結果のリスクスコアリング**。fixed-asset-ashigaru の LLM 判定結果に信頼度スコアを付与し、低スコア案件を自動でレビューキューに回す仕組み

---

### 記事4: バックオフィス業務のAIサービスを調べてみる

- **URL**: https://zenn.dev/banboobloom/articles/2025031500001
- **技術スタック**: sweeep（AI-OCR仕訳自動化）、LayerX INVOICE、LegalForce（契約書レビュー）、hitTO（AIチャットボット）
- **設計アプローチ**:
  - 経理: 紙の請求書・領収書 → AI-OCR → データ化 → 仕訳・振込処理まで自動化
  - 法務: 契約書レビューAI が不利な条文・抜け漏れ条項を自動検出
  - 全分野共通: 「評価基準のブレや属人化」をAIで標準化
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: エンドツーエンドの自動化（OCR→仕訳→振込）、不正検知機能
  - **劣っている点**: 既製SaaSの紹介であり、カスタマイズ性は限定的
- **取り入れるべき改善点**: **判定基準の標準化**。ポリシーベースの判定ルールを明文化し、属人化を防ぐ設計。判定理由の説明文をLLMに生成させることで透明性を確保

---

### 記事5: 【FastAPI-MCP】既存のAPIを数行のコードで「LLMフレンドリー」にする方法

- **URL**: https://zenn.dev/atsukish/articles/5ded6e7a29c86b
- **技術スタック**: FastAPI、FastAPI-MCP ライブラリ、MCP（Model Context Protocol）
- **設計アプローチ**:
  - 既存の FastAPI エンドポイントに数行追加で MCP 対応
  - 安全な読み取り専用操作（GET）のみを先に公開する段階的アプローチ
  - `operation_id` で明示的なツール名を付与（LLM が正しく呼び出せるようにする）
  - ツールの description がLLMへの「取扱説明書」として機能
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: LLMエージェントからAPIを直接呼び出せるMCP対応
  - **劣っている点**: MCP対応のみでUI/業務ロジックは別途必要
- **取り入れるべき改善点**: **FastAPI エンドポイントのMCP対応**。将来的にAIエージェントから固定資産判定APIを直接呼び出せるようにすることで、他システムとの連携が容易になる

---

### 記事6: Python + FastAPIでオニオンアーキテクチャ（簡易版）

- **URL**: https://zenn.dev/keitakn/articles/python-fastapi-onion-architecture-simplified
- **技術スタック**: FastAPI、Python Protocol（インターフェース定義）、aiomysql、OpenAI API、mypy
- **設計アプローチ**:
  - **Domain層**: 純粋なビジネスロジック（フレームワーク非依存）
  - **Usecase層**: アプリケーション固有のワークフロー（DTOで入出力）
  - **Presentation層**: HTTPルーティング、リクエスト/レスポンス処理
  - **Infrastructure層**: リポジトリ実装（DB、外部API）。LLMライブラリの切り替えも容易
  - テスト戦略: Usecase 層を重点テスト、リポジトリは実DBでテスト
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: レイヤー分離によるテスタビリティ、LLMプロバイダの切り替え容易性
  - **劣っている点**: 初期の実装コストが高い、小規模プロジェクトにはオーバーエンジニアリングの可能性
- **取り入れるべき改善点**: **LLM呼び出しのリポジトリパターン化**。判定ロジックをInfrastructure層のリポジトリとして抽象化すれば、OpenAI → Claude → ローカルLLM 等の切り替えがビジネスロジックに影響しない

---

### 記事7: Streamlit in Snowflake、新卒1年目が業務アプリを作ってみた話

- **URL**: https://zenn.dev/nttdata_tech/articles/ccdcdeb7fc195a
- **技術スタック**: Streamlit in Snowflake、Python、ChatGPT（開発補助）
- **設計アプローチ**:
  - 3つの別々のワークフローを**単一画面に統合**
  - Snowflake テーブルとの直接連携（中間API不要）
  - CRUD操作をフォームベースで実装
  - 生成AIとの「ペアプログラミング」で開発
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: 単一画面完結のUX設計、Snowflakeネイティブのデータ連携
  - **劣っている点**: Snowflake環境依存、汎用性に限界
- **取り入れるべき改善点**: **単一画面完結のUX設計思想**。固定資産判定のワークフロー（PDF アップロード → 抽出確認 → 判定結果 → 修正 → 確定）を1画面で完結させる設計

---

### 記事8: 社内向けStreamlitのデプロイの現実解

- **URL**: https://zenn.dev/dataheroes/articles/2eae5a5ad92534
- **技術スタック**: Cloudflare Tunnel + Cloudflare Access、Streamlit in Snowflake、Squadbase
- **設計アプローチ**:
  - **Cloudflare Tunnel**: アウトバウンド接続のみでインバウンドトラフィック受信。ファイアウォール開放不要、自動SSL
  - **Cloudflare Access**: リバースプロキシとして認証代行。Google/Microsoft SSO連携、部門別アクセス制御
  - 開発者は認証コード不要（インフラレベルで解決）
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: 認証をアプリ外で解決する設計、ゼロトラストセキュリティ
  - **劣っている点**: Cloudflareへの依存
- **取り入れるべき改善点**: **Cloudflare Tunnel によるセキュアなデプロイ**。社内利用を想定するなら、アプリ側で認証を実装するよりインフラレベルでの認証が運用負荷を大幅に下げる

---

### 記事9: Slack × FastAPI で作る！社内 AI アシスタント基盤

- **URL**: https://zenn.dev/bubbles/articles/806ef7cc449bf3
- **技術スタック**: FastAPI、Slack Bolt、LangChain、OpenAI/Azure、Redis、Uvicorn/Gunicorn
- **設計アプローチ**:
  - FastAPI がHTTPリクエストをルーティング → Slack Bolt がイベント処理
  - LangChain でプロンプト + 会話履歴 + LLM をチェーン化
  - マルチワーカー環境で Redis によるスレッド管理（TTLベース）
  - RAG 拡張を前提とした基盤設計
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: Slack連携による通知・対話インターフェース、Redis によるスケーラビリティ
  - **劣っている点**: WebアプリとしてのリッチなUI/UXが不足
- **取り入れるべき改善点**: **LangChainによるプロンプト管理のチェーン化**。判定ルール、コンテキスト、ユーザー入力を構造的に組み合わせるパターン。また**判定結果のSlack通知**機能も有用

---

### 記事10: LLMアプリケーションの評価入門〜基礎から運用まで

- **URL**: https://zenn.dev/pharmax/articles/df59290ba875ff
- **技術スタック**: LLM評価フレームワーク全般
- **設計アプローチ**:
  - **3レイヤー評価**: L1=出力品質（Ground Truth比較）、L2=ユーザー行動（先行指標）、L3=ビジネスインパクト
  - オフライン評価（事前データセット）とオンライン評価（本番データ）の両輪
  - 「オフラインのパフォーマンスはヘルスチェックに過ぎない」という警告
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: 体系的なLLM評価フレームワーク
  - **劣っている点**: 理論的な記事で具体的な実装例が限定的
- **取り入れるべき改善点**: **LLM判定精度の定量評価基盤**。正解データセットを用意し、判定精度を定期的にオフライン評価する仕組み。判定結果のユーザー修正データをフィードバックとして活用

---

### 記事11: LangChain・FastAPI・ReactでGPTチャットアプリを作成する

- **URL**: https://zenn.dev/ktechb/articles/langchain-react-fastapi
- **技術スタック**: FastAPI（バックエンド）、LangChain（LLM連携）、React + TypeScript（フロント）、Tailwind CSS、openapi-generator-cli
- **設計アプローチ**:
  - FastAPI が OpenAPI ドキュメントを自動生成 → フロントエンドがTypeScript APIクライアントを自動生成
  - LangChain のプロンプトテンプレートで GPT-3 を呼び出し
  - スキーマ駆動開発（OpenAPI → TypeScript 自動生成）
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: OpenAPI スキーマ駆動のフロント-バック連携、型安全なAPI呼び出し
  - **劣っている点**: プロトタイプ段階で会話履歴の永続化なし
- **取り入れるべき改善点**: **OpenAPIスキーマ駆動のAPI設計**。FastAPI の自動ドキュメント生成を活用し、フロントエンド（Streamlit でなくても）との連携を型安全にする

---

### 記事12: LLM の効果的な社会実装（社内生成AIハッカソン）

- **URL**: https://zenn.dev/streamwest1629/articles/llm-hackathon_2024
- **技術スタック**: AWS Bedrock（Claude 3 Haiku）、Amazon Transcribe、Terraform
- **設計アプローチ**:
  - LLMの汎用性をあえて**制限**し、特定ユースケースに特化させることでユーザビリティ向上
  - 非決定的な出力を強みとして活用（「不確定な概念にあたりをつける」用途）
  - AI利用を**意図的にUIから隠す**ことで、「AIだから信用しない」というバイアスを回避
- **fixed-asset-ashigaru との比較**:
  - **優れている点**: LLM活用の「制約設計」という思想、UXにおけるAI存在感の調整
  - **劣っている点**: 特定ユースケース向けで汎用性なし
- **取り入れるべき改善点**: **LLMの機能を意図的に制約する設計**。固定資産判定という明確なスコープに絞り込むことで精度向上。また判定UIで「AIが判定した」ことを前面に出しすぎず、**結果と根拠の提示**に集中する設計

---

## 総合分析

### 1. 技術スタックの傾向

| 要素 | 主流パターン | fixed-asset-ashigaru の現状 | ギャップ |
|------|-------------|---------------------------|---------|
| **OCR** | Document AI / Gemini | PDFテキスト抽出 | LLMベースの構造化抽出を検討 |
| **LLM統合** | LangChain チェーン化 | 直接LLM呼び出し | プロンプト管理の構造化が有用 |
| **バックエンド** | FastAPI + オニオンアーキテクチャ | FastAPI | レイヤー分離でテスタビリティ向上可能 |
| **UI** | Streamlit / React | Streamlit | 現状で適切 |
| **デプロイ** | Cloudflare Tunnel + Access | （未記載） | 社内デプロイに最適解 |
| **評価** | 3レイヤー評価、正解データセット | （未記載） | 判定精度の定量評価基盤が必要 |

### 2. 会計・経理AI領域の共通パターン

先行事例から見えた共通パターン:

1. **「AI提案 → 人間承認」モデル**: 完全自動化ではなく、人間のレビューを組み込む設計が標準
2. **信頼度スコアの可視化**: OCR精度やLLM判定の信頼度をユーザーに表示し、低信頼度の案件を優先レビュー
3. **継続学習サイクル**: 人間の修正をフィードバックとして精度を向上させる仕組み
4. **異常検知の併用**: 通常パターンからの逸脱を自動検出

### 3. fixed-asset-ashigaru に取り入れるべき優先改善点

| 優先度 | 改善点 | 根拠記事 | 効果 |
|--------|--------|---------|------|
| **高** | LLM判定の信頼度スコア表示 | 記事1, 3 | ユーザーの判断負荷軽減、レビュー効率化 |
| **高** | 判定精度の定量評価基盤 | 記事10 | 品質の可視化・改善サイクルの確立 |
| **高** | 判定理由の説明文生成 | 記事4, 12 | 透明性向上、属人化防止 |
| **中** | LLM呼び出しのリポジトリパターン化 | 記事6 | LLMプロバイダ切り替え容易性 |
| **中** | Cloudflare Tunnel でのセキュアデプロイ | 記事8 | 社内利用時のセキュリティ・運用負荷削減 |
| **中** | プロンプト管理の構造化（LangChain等） | 記事9, 11 | 判定ルール管理の保守性向上 |
| **低** | FastAPI エンドポイントのMCP対応 | 記事5 | 将来のAIエージェント連携 |
| **低** | 単一画面完結のワークフロー設計 | 記事7 | UX向上 |

### 4. 先行事例から得られる教訓

1. **「数字を出せ」** — LLM判定は「正解/不正解」だけでなく信頼度スコアを付与し、定量的な評価基盤を構築すべき。Booking.com の知見「オフラインのパフォーマンスはヘルスチェックに過ぎない」を肝に銘じよ

2. **「人間を信じろ」** — 会計・経理領域では完全自動化より「AI提案→人間承認」モデルが主流。fixed-asset-ashigaru もLLM判定結果を最終回答ではなく「提案」として位置づけ、人間のレビューフローを組み込むべき

3. **「制約は武器」** — LLMの汎用性をあえて制限し、固定資産判定に特化させることで精度と信頼性が向上。スコープを狭めることはデメリットではなく設計上の強み

4. **「アーキテクチャは将来の自分を助ける」** — オニオンアーキテクチャやリポジトリパターンでLLM呼び出しを抽象化しておくと、プロバイダ変更やプロンプト改善が既存ロジックに影響しない
